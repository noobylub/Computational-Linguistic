{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noobylub/Computational-Linguistic/blob/master/ComputingPairwise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem setting\n",
        "\n",
        "In the class, we faced the problem of computing all pairwise distances between rows of matrices A and B. We used a loop over the rows of one of the matrices to save time, but this is terribly slow because it cannot be parallelised and because Python loops are slow in general. We can do better.\n",
        "\n",
        "Below are two ways of doing this in a matrix-oriented way. The first way relies on first copying the data and then working with now-aligned pairs of rows. This wastes memory and time on data copying, but the upside is that when the rows are correctly aligned, you can then apply any function to them, not necessarily the Euclidean distance.\n",
        "\n",
        "The second option is much cleaner, but it relies on the definition of Euclidean distance. You can compute pairwise cosine similarities in a similar (and even simpler) way, but other distance measures, e.g. Manhattan distance, will only work with the first approach."
      ],
      "metadata": {
        "id": "oqfHoe2E77am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1: Copy, then compute\n",
        "\n",
        "If A has m rows and B has n rows, we need to construct m-times-n pairs of rows. This amounts to copying A n times, B m times and rearranging the rows."
      ],
      "metadata": {
        "id": "36hLTNja9Eap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nBn_olFc73x9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "m = 13\n",
        "n = 11\n",
        "c = 20\n",
        "\n",
        "A = np.random.rand(m, c)\n",
        "B = np.random.rand(n, c)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_indices = list(range(A.shape[0]))   # 0, 1, 2, 3, ..., m-1\n",
        "# n copies of the first row of A, then n copies of the second row of A, etc.\n",
        "# We're copying a list and then sorting -- the idiomatic numpy for this is `repeat`,\n",
        "# which will produce n copies of the first element, followed by n copies of the\n",
        "# second element, etc.\n",
        "A_indices = sorted(A_indices * n)     # 0, 0, 0, ..., m-1, m-1\n",
        "A_aligned = A[A_indices]\n",
        "\n",
        "# n copies of each row of A should map to n rows of B in the original order\n",
        "# We're copying a list without sorting -- the idiomatic numpy for this is `tile`,\n",
        "# which will copy the whole array along a new axis.\n",
        "B_indices = list(range(B.shape[0]))\n",
        "B_aligned = B[B_indices * m]\n",
        "\n",
        "# This will give a vector of length m*n, which we convert into a distance\n",
        "# matrix\n",
        "distances_1 = np.linalg.norm(A_aligned - B_aligned, axis=1).reshape(m, n)"
      ],
      "metadata": {
        "id": "r71VEpGF9h_3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was better than looping, but actually we can use broadcasting behaviour of Numpy to express this more succinctly."
      ],
      "metadata": {
        "id": "c0HD2D60_hzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_aligned = A.reshape(m, 1, c)  # or A[:, None, :]\n",
        "B_aligned = B.reshape(1, n, c)  # or B[None, :, :]\n",
        "\n",
        "# In order to obtain a matching shape, numpy will broadcast B_aligned\n",
        "# along the second dimension and A_aligned along the first dimension.\n",
        "# Now, however, we a have 3d array of shape (m, n, c), so we need to\n",
        "# take the norm of the difference along the third axis.\n",
        "distances_2 = np.linalg.norm(A_aligned - B_aligned, axis=2)"
      ],
      "metadata": {
        "id": "oeKPDEcP-O9e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A_aligned.shape"
      ],
      "metadata": {
        "id": "m6C7XhC73PNw",
        "outputId": "2a0fa2ff-a7c9-4c45-906e-b6480874a182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 1, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B_aligned.shape"
      ],
      "metadata": {
        "id": "xuE0-oDz3R7b",
        "outputId": "e49f335c-6425-4f34-c75a-953db78042f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 11, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distances_2.shape"
      ],
      "metadata": {
        "id": "pOIGSYoT3VMz",
        "outputId": "f427d496-ad03-4a87-e77f-758f843f9a75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.allclose(distances_1, distances_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCwbZfu6AzF9",
        "outputId": "49d98914-2936-48a9-d3f9-3fbdda5ef7b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2: Using the properties of Euclidean distance\n",
        "\n",
        "By definition, $$ D(\\vec{u}, \\vec{v}) = \\sqrt{\\sum_{i=1}^d (\\vec{u}_i - \\vec{v}_i)^2 } $$\n",
        "\n",
        "where $d$ is the dimensionality of the vectors. Expanding all summands, we get\n",
        "\n",
        "$$ D(\\vec{u}, \\vec{v}) = (\n",
        "    \\vec{u}_1^2 - 2\\vec{u}_1\\vec{v}_1 + \\vec{v}_1^2 + \\\\\n",
        "    \\vec{u}_2^2 - 2\\vec{u}_2\\vec{v}_2 + \\vec{v}_2^2 + \\\\\n",
        "    \\dots + \\vec{u}_d^2 - 2\\vec{u}_d\\vec{v}_d + \\vec{v}_d^2\n",
        ")^{1/2}$$\n",
        "\n",
        "If we group together all the squared elements of $\\vec{u}$ and $\\vec{v}$ and the stuff in between we see that by definition of the dot product of two vectors is actually equivalent to\n",
        "\n",
        "$$ D(\\vec{u}, \\vec{v}) = (\\vec{u} \\cdot \\vec{u} -2 \\vec{u} \\cdot \\vec{v} + \\vec{v} \\cdot \\vec{v})^{1/2} $$\n",
        "\n",
        "And since matrix multiplication is exactly taking dot products of all pairs of rows or columns of two matrices (depending on how we orient them), we can first compute $-2AB^T$ to get a matrix of size (m, n) and then add sums of squares of rows of A to each row and sums of squares of rows of B to each column to get pairwise distances.\n",
        "\n",
        "Now we don't need to copy the data to align the rows and only store two additional vectors for sums of squares."
      ],
      "metadata": {
        "id": "PfRgmAfYDkpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_sums = np.sum(np.square(A), axis=1)\n",
        "B_sums = np.sum(np.square(B), axis=1)\n",
        "distances_3 = np.sqrt(\n",
        "    # Elements of A_sums are replicated over columns (each row should contain the same element several times),\n",
        "    # so we represent it is a single-column matrix.\n",
        "    # Elements of B_sums are copied over rows, so we represent it as a single-row matrix\n",
        "    -2 * np.dot(A, B.T) + A_sums.reshape(-1, 1) + B_sums.reshape(1, -1)\n",
        ")"
      ],
      "metadata": {
        "id": "O5v20wdFA8LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.allclose(distances_1, distances_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGFZfwSKI5n3",
        "outputId": "1e62821c-6a25-428f-e9a6-fe5dec4634de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}