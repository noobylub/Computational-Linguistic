{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ9OpSwxbL78"
      },
      "source": [
        "# Week 10 Seminar notebook: Multilayer neural networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXB5BzEZbxBQ"
      },
      "source": [
        "Problem 1: Given the weights and the input vector below, write the code to calculate the predicted output value y_hat, assuming the model described in the week 9 lecture."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "65TAyk5HZfX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Iv7l63pebdmD",
        "outputId": "bce63498-595b-4d4f-96f3-348f47321b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.38 -0.77  0.72]]\n",
            "[[0.   0.   0.72]]\n",
            "[[0.2736]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "weights_0_1=np.array([[-.59,.75,-.95],[.34,-.17,.12],[-.72,-.6,.6]])\n",
        "weights_1_2=np.array([[.93],[-.37],[.38]])\n",
        "layer_0 = np.array([[ 0, 1, 1 ]])\n",
        "\n",
        "# Essentially repeats the step\n",
        "# Due to the syntax in python, you have to transpose first\n",
        "# q_layer_1 =  weights_0_1.dot(layer_0.T)\n",
        "q_layer_1_comparison = layer_0.dot(weights_0_1)\n",
        "print(q_layer_1_comparison)\n",
        "\n",
        "\"\"\"\n",
        "# For q_layer_1\n",
        "#  [[-0.2 ]\n",
        "#  [-0.05]\n",
        "#  [ 0.  ]]\n",
        "# For q_layer_1_comparison\n",
        "# [[-0.2  -0.05  0.  ]]\n",
        "# As seen in comparison above, the direction of vectors are different\n",
        "\"\"\"\n",
        "\n",
        "# print(q_layer_1)\n",
        "q_layer_1 = np.maximum(q_layer_1_comparison,[0,0,0])\n",
        "print(q_layer_1)\n",
        "z_1 = q_layer_1.dot(weights_1_2)\n",
        "print(z_1)\n",
        "# # q_layer_2 = weights_1_2.dot(q_layer_1.T)\n",
        "\n",
        "# Relu layer\n",
        "# layer_1 = np.maximum(q_layer_1,0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baXh3EhjbdmD"
      },
      "source": [
        "Problem 2: Given the true label y=1, and the learning rate as specified below, write the code to perform the backwards pass and update the weights. You should obtain the same weights at t2 as on the week 9 slides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pbsTDtMobdmD",
        "outputId": "1bc5d1ad-b974-4908-ee67-b0f22ccd505c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.7264]]\n",
            "[[-0.  0.  0.]\n",
            " [ 0.  0.  0.]\n",
            " [ 0.  0.  0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2649343825.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  layer_1_delta[0,0]= layer_2_del * weights_1_2[0,0] * (q_layer_1[0,0]>0)\n",
            "/tmp/ipython-input-2649343825.py:11: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  layer_1_delta[0,1]= layer_2_del * weights_1_2[0,0] * (q_layer_1[0,1]>0)\n",
            "/tmp/ipython-input-2649343825.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  layer_1_delta[0,2]= layer_2_del * weights_1_2[0,0] * (q_layer_1[0,2]>0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 1 is out of bounds for axis 0 with size 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2649343825.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlayer_1_delta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlayer_2_del\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights_1_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq_layer_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlayer_1_delta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlayer_2_del\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights_1_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq_layer_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mlayer_1_delta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlayer_2_del\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights_1_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq_layer_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlayer_1_delta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlayer_2_del\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights_1_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq_layer_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
          ]
        }
      ],
      "source": [
        "true_label = np.array([[1]])\n",
        "learning_rate=0.2\n",
        "\n",
        "layer_2_del = z_1 - true_label\n",
        "print(layer_2_del)\n",
        "layer_1_delta=np.zeros((3,3))\n",
        "\n",
        "\n",
        "# Basically in backpropagation\n",
        "# layer_1_delta[0,0]= layer_2_del * weights_1_2[0,0] * (q_layer_1[0,0]>0)\n",
        "# print(layer_1_delta)\n",
        "# layer_1_delta[0,1]= layer_2_del * weights_1_2[0,1] * (q_layer_1[0,1]>0)\n",
        "# layer_1_delta[0,2]= layer_2_del * weights_1_2[0,2] * (q_layer_1[0,2]>0)\n",
        "\n",
        "# layer_1_delta[1,0]= layer_2_del * weights_1_2[0,0] * (q_layer_1[1,0]>0)\n",
        "# layer_1_delta[1,1]= layer_2_del * weights_1_2[] * (q_layer_1[1,1]>0)\n",
        "# layer_1_delta[1,2]= layer_2_del * weights_1_2[1,0] * (q_layer_1[1,2]>0)\n",
        "\n",
        "# layer_1_delta[2,0]= layer_2_del * weights_1_2[2,0] * (q_layer_1[2,0]>0)\n",
        "# layer_1_delta[2,1]= layer_2_del * weights_1_2[2,0] * (q_layer_1[2,1]>0)\n",
        "# layer_1_delta[2,2]= layer_2_del * weights_1_2[2,0] * (q_layer_1[2,2]>0)\n",
        "# print(layer_1_delta)\n",
        "# # weights_0_1[0,0] -= layer_1_delta[0,0] * learning_rate\n",
        "# # weights_0_1[0,1] -= layer_1_delta[0,1] * learning_rate\n",
        "# # weights_0_1[0,2] -= layer_1_delta[0,2] * learning_rate\n",
        "# # weights_0_1[1,0] -= layer_1_delta[1,0] * learning_rate\n",
        "# # weights_0_1[1,1] -= layer_1_delta[1,1] * learning_rate\n",
        "# # weights_0_1[1,2] -= layer_1_delta[1,2] * learning_rate\n",
        "# # weights_0_1[2,0] -= layer_1_delta[2,0] * learning_rate\n",
        "# # weights_0_1[2,1] -=map\n",
        "# # weights_0_1[2,2] -=\n",
        "\n",
        "# # weights_1_2[0] -=\n",
        "# # weights_1_2[1] -=\n",
        "# # weights_1_2[2] -=\n",
        "\n",
        "# # print(weight_0_1)\n",
        "# # print(weight_1_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTSJWN9JbdmE"
      },
      "source": [
        "Problem 3. Given the training data below, complete the code to train the network to solve the problem. You can use the code in the block below the training block to test that the models predictions from the training inputs are approximately correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er0Gc1jWbdmE"
      },
      "outputs": [],
      "source": [
        "inputs = np.array( [[ 0, 0, 1 ],\n",
        "                          [ 0, 1, 1 ],\n",
        "                          [ 1, 0, 1 ],\n",
        "                          [ 1, 1, 1 ] ] )\n",
        "\n",
        "true_labels = np.array([ [0], [1], [1], [0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxpMsPmCbdmE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "learning_rate = 0.35\n",
        "num_features=3\n",
        "hidden_size = 3\n",
        "np.random.seed(1)\n",
        "weights_0_1 = np.random.rand(num_features,hidden_size)\n",
        "np.random.seed(1)\n",
        "weights_1_2 = np.random.rand(hidden_size,1)\n",
        "\n",
        "loss = []\n",
        "n_iters=1000\n",
        "for iteration in range(n_iters):\n",
        "   layer_2_error = 0\n",
        "   for i in range(len(inputs)):\n",
        "      layer_0 = inputs[i]\n",
        "      #print(\"L0:\")\n",
        "      #print(layer_0)\n",
        "      ## Add forward pass\n",
        "      layer_1 =\n",
        "      layer_2 =\n",
        "\n",
        "      layer_2_error+=np.sum((layer_2-true_labels[i])**2)\n",
        "\n",
        "      ## Add backward pass and update weights\n",
        "\n",
        "      layer_2_delta =\n",
        "\n",
        "      layer_1_delta=np.zeros((3,3))\n",
        "      layer_1_delta[0,0]=\n",
        "      layer_1_delta[0,1]=\n",
        "      layer_1_delta[0,2]=\n",
        "\n",
        "      layer_1_delta[1,0]=\n",
        "      layer_1_delta[1,1]=\n",
        "      layer_1_delta[1,2]=\n",
        "\n",
        "      layer_1_delta[2,0]=\n",
        "      layer_1_delta[2,1]=\n",
        "      layer_1_delta[2,2]=\n",
        "\n",
        "      weights_0_1[0,0] -=\n",
        "      weights_0_1[0,1] -=\n",
        "      weights_0_1[0,2] -=\n",
        "      weights_0_1[1,0] -=\n",
        "      weights_0_1[1,1] -=\n",
        "      weights_0_1[1,2] -=\n",
        "      weights_0_1[2,0] -=\n",
        "      weights_0_1[2,1] -=\n",
        "      weights_0_1[2,2] -=\n",
        "\n",
        "      weights_1_2[0] -=\n",
        "      weights_1_2[1] -=\n",
        "      weights_1_2[2] -=\n",
        "\n",
        "\n",
        "   loss.append(layer_2_error)\n",
        "plt.plot(range(1,n_iters),loss[1:])\n",
        "plt.xlabel(\"number of epochs\")\n",
        "plt.ylabel(\"loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SGzn9jpj5TP"
      },
      "source": [
        "You can view the results as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tb8iwombdmE"
      },
      "outputs": [],
      "source": [
        "np. set_printoptions(suppress=True)\n",
        "for k in range(4):\n",
        "  layer_0 = inputs[k]\n",
        "  layer_1 = np.maximum(np.dot(layer_0,weights_0_1),0)\n",
        "  layer_2 = np.dot(layer_1,weights_1_2)\n",
        "  print(layer_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPgyCKBxkOWa"
      },
      "source": [
        "Problem 4: Once you have a model that makes good predictions, try lowering the learning rate. What do you notice? Why do you think this happens?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05hmP4oHfUKx"
      },
      "source": [
        "Problem 5. Examine the weights in your model. Give a verbal explanation of why they give the correct answer to the XOR problem"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 6 (hard problem to try if you have time): rewrite the code you wrote above so that it calculates deltas and updates weights using vector and/or matrix operations rather than element by element"
      ],
      "metadata": {
        "id": "cxD8-MiiIkxq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}