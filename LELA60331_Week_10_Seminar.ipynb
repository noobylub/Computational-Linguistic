{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ9OpSwxbL78"
      },
      "source": [
        "# Week 10 Seminar notebook: Multilayer neural networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXB5BzEZbxBQ"
      },
      "source": [
        "Problem 1: Given the weights and the input vector below, write the code to calculate the predicted output value y_hat, assuming the model described in the week 9 lecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Iv7l63pebdmD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "weights_0_1=np.array([[-.59,.75,-.95],[.34,-.17,.12],[-.72,-.6,.6]])\n",
        "weights_1_2=np.array([[.93],[-.37],[.38]])\n",
        "layer_0 = np.array([[ 0, 1, 1 ]])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_1 = np.maximum(np.dot(layer_0,weights_0_1),0)\n",
        "layer_2 = np.dot(layer_1,weights_1_2)\n",
        "print(layer_2)"
      ],
      "metadata": {
        "id": "YE1CQhG5I9U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baXh3EhjbdmD"
      },
      "source": [
        "Problem 2: Given the true label y=1, and the learning rate as specified below, write the code to perform the backwards pass and update the weights. You should obtain the same weights at t2 as on the week 9 slides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbsTDtMobdmD"
      },
      "outputs": [],
      "source": [
        "true_label = np.array([[1]])\n",
        "learning_rate=0.2\n",
        "layer_2_diff = (layer_2 - true_label)\n",
        "layer_1_delta=np.zeros((3,3))\n",
        "\n",
        "layer_1_delta[0,0]=layer_2_diff*weights_1_2[0]*(layer_1[0,0]>0)*layer_0[0,0]\n",
        "layer_1_delta[0,1]=layer_2_diff*weights_1_2[1]*(layer_1[0,1]>0)*layer_0[0,0]\n",
        "layer_1_delta[0,2]=layer_2_diff*weights_1_2[2]*(layer_1[0,2]>0)*layer_0[0,0]\n",
        "\n",
        "layer_1_delta[1,0]=layer_2_diff*weights_1_2[0]*(layer_1[0,0]>0)*layer_0[0,1]\n",
        "layer_1_delta[1,1]=layer_2_diff*weights_1_2[1]*(layer_1[0,1]>0)*layer_0[0,1]\n",
        "layer_1_delta[1,2]=layer_2_diff*weights_1_2[2]*(layer_1[0,2]>0)*layer_0[0,1]\n",
        "\n",
        "layer_1_delta[2,0]=layer_2_diff*weights_1_2[0]*(layer_1[0,0]>0)*layer_0[0,2]\n",
        "layer_1_delta[2,1]=layer_2_diff*weights_1_2[1]*(layer_1[0,1]>0)*layer_0[0,2]\n",
        "layer_1_delta[2,2]=layer_2_diff*weights_1_2[2]*(layer_1[0,2]>0)*layer_0[0,2]\n",
        "\n",
        "\n",
        "weights_0_1[0,0] -= learning_rate * layer_1_delta[0,0]\n",
        "weights_0_1[0,1] -= learning_rate * layer_1_delta[0,1]\n",
        "weights_0_1[0,2] -= learning_rate * layer_1_delta[0,2]\n",
        "weights_0_1[1,0] -= learning_rate * layer_1_delta[1,0]\n",
        "weights_0_1[1,1] -= learning_rate * layer_1_delta[1,1]\n",
        "weights_0_1[1,2] -= learning_rate * layer_1_delta[1,2]\n",
        "weights_0_1[2,0] -= learning_rate * layer_1_delta[2,0]\n",
        "weights_0_1[2,1] -= learning_rate * layer_1_delta[2,1]\n",
        "weights_0_1[2,2] -= learning_rate * layer_1_delta[2,2]\n",
        "\n",
        "\n",
        "weights_1_2[0] -= (learning_rate * (layer_1[0,0]*layer_2_diff))[0]\n",
        "weights_1_2[1] -= (learning_rate * (layer_1[0,1]*layer_2_diff))[0]\n",
        "weights_1_2[2] -= (learning_rate * (layer_1[0,2]*layer_2_diff))[0]\n",
        "\n",
        "print(weights_0_1)\n",
        "print(weights_1_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A more succinct version"
      ],
      "metadata": {
        "id": "BYuF3De0JKhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_label = np.array([[1]])\n",
        "learning_rate=0.2\n",
        "layer_2_diff = (layer_2 - true_label)\n",
        "\n",
        "layer_1_delta = (weights_1_2*layer_2_diff)*(layer_1>0).T*layer_0\n",
        "\n",
        "\n",
        "weights_0_1 -= learning_rate*layer_1_delta.T\n",
        "\n",
        "\n",
        "weights_1_2 -= learning_rate * (layer_1*layer_2_diff).T\n",
        "\n",
        "\n",
        "print(weights_0_1)\n",
        "print(weights_1_2)"
      ],
      "metadata": {
        "id": "GQ7qyNluJI7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTSJWN9JbdmE"
      },
      "source": [
        "Problem 3. Given the training data below, complete the code to train the network to solve the problem. You can use the code in the block below the training block to test that the models predictions from the training inputs are approximately correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er0Gc1jWbdmE"
      },
      "outputs": [],
      "source": [
        "inputs = np.array( [[ 0, 0, 1 ],\n",
        "                          [ 0, 1, 1 ],\n",
        "                          [ 1, 0, 1 ],\n",
        "                          [ 1, 1, 1 ] ] )\n",
        "\n",
        "true_labels = np.array([ [0], [1], [1], [0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxpMsPmCbdmE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "learning_rate = 0.35\n",
        "num_features=3\n",
        "hidden_size = 3\n",
        "np.random.seed(1)\n",
        "weights_0_1 = np.random.rand(num_features,hidden_size)\n",
        "np.random.seed(1)\n",
        "weights_1_2 = np.random.rand(hidden_size,1)\n",
        "loss = []\n",
        "n_iters=1000\n",
        "for iteration in range(n_iters):\n",
        "   layer_2_error = 0\n",
        "   for i in range(len(inputs)):\n",
        "      layer_0 = inputs[i]\n",
        "\n",
        "      ## Add forward pass\n",
        "      layer_1 = np.maximum(np.dot(layer_0,weights_0_1),0)\n",
        "      layer_2 = np.dot(layer_1,weights_1_2)\n",
        "\n",
        "\n",
        "      ## Add backward pass and update weights\n",
        "      layer_2_error+=np.sum((layer_2-true_labels[i])**2)\n",
        "\n",
        "      layer_2_diff = (layer_2 - true_labels[i])\n",
        "\n",
        "      layer_1_delta=np.zeros((3,3))\n",
        "      layer_1_delta[0,0]=layer_2_diff*weights_1_2[0]*(layer_1[0]>0)*layer_0[0]\n",
        "      layer_1_delta[0,1]=layer_2_diff*weights_1_2[1]*(layer_1[1]>0)*layer_0[0]\n",
        "      layer_1_delta[0,2]=layer_2_diff*weights_1_2[2]*(layer_1[2]>0)*layer_0[0]\n",
        "\n",
        "      layer_1_delta[1,0]=layer_2_diff*weights_1_2[0]*(layer_1[0]>0)*layer_0[1]\n",
        "      layer_1_delta[1,1]=layer_2_diff*weights_1_2[1]*(layer_1[1]>0)*layer_0[1]\n",
        "      layer_1_delta[1,2]=layer_2_diff*weights_1_2[2]*(layer_1[2]>0)*layer_0[1]\n",
        "\n",
        "      layer_1_delta[2,0]=layer_2_diff*weights_1_2[0]*(layer_1[0]>0)*layer_0[2]\n",
        "      layer_1_delta[2,1]=layer_2_diff*weights_1_2[1]*(layer_1[1]>0)*layer_0[2]\n",
        "      layer_1_delta[2,2]=layer_2_diff*weights_1_2[2]*(layer_1[2]>0)*layer_0[2]\n",
        "\n",
        "      weights_0_1[0,0] -= learning_rate * layer_1_delta[0,0]\n",
        "      weights_0_1[0,1] -= learning_rate * layer_1_delta[0,1]\n",
        "      weights_0_1[0,2] -= learning_rate * layer_1_delta[0,2]\n",
        "      weights_0_1[1,0] -= learning_rate * layer_1_delta[1,0]\n",
        "      weights_0_1[1,1] -= learning_rate * layer_1_delta[1,1]\n",
        "      weights_0_1[1,2] -= learning_rate * layer_1_delta[1,2]\n",
        "      weights_0_1[2,0] -= learning_rate * layer_1_delta[2,0]\n",
        "      weights_0_1[2,1] -= learning_rate * layer_1_delta[2,1]\n",
        "      weights_0_1[2,2] -= learning_rate * layer_1_delta[2,2]\n",
        "\n",
        "      weights_1_2[0] -= (learning_rate * (layer_1[0]*layer_2_diff))\n",
        "      weights_1_2[1] -= (learning_rate * (layer_1[1]*layer_2_diff))\n",
        "      weights_1_2[2] -= (learning_rate * (layer_1[2]*layer_2_diff))\n",
        "\n",
        "\n",
        "   loss.append(layer_2_error)\n",
        "plt.plot(range(1,n_iters),loss[1:])\n",
        "plt.xlabel(\"number of epochs\")\n",
        "plt.ylabel(\"loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SGzn9jpj5TP"
      },
      "source": [
        "You can view the results as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tb8iwombdmE"
      },
      "outputs": [],
      "source": [
        "np. set_printoptions(suppress=True)\n",
        "for k in range(4):\n",
        "  layer_0 = inputs[k]\n",
        "  layer_1 = np.maximum(np.dot(layer_0,weights_0_1),0)\n",
        "  layer_2 = np.dot(layer_1,weights_1_2)\n",
        "  print(layer_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPgyCKBxkOWa"
      },
      "source": [
        "Problem 4: Once you have a model that makes good predictions, try lowering the learning rate. What do you notice? Why do you think this happens?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05hmP4oHfUKx"
      },
      "source": [
        "Problem 5. Examine the weights in your model. Give a verbal explanation of why they give the correct answer to the XOR problem"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 6 (hard problem to try if you have time): rewrite the code you wrote above so that it calculates deltas and updates weights using vector and/or matrix operations rather than element by element"
      ],
      "metadata": {
        "id": "cxD8-MiiIkxq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}